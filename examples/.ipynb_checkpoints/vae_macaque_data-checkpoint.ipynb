{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import scipy.special as ssp\n",
    "import sys\n",
    "import scipy.io as sio\n",
    "sys.path.append(\"../code/\")\n",
    "from vae import *\n",
    "from util import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "## import plot packages\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from matplotlib import ticker\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load macaque data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load trial information\n",
    "## starttime, endtime, number, tgtontime, gocuetime, tgtdir, tgtid\n",
    "trial_dat = sio.loadmat(\"../data/chewie_data/Chewie_20161006_trials_array.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load spike data\n",
    "dat_ = sio.loadmat('../data/chewie_data/Chewie_20161006_seq.mat');\n",
    "\n",
    "dat_all = [[] for _ in range(8)];\n",
    "tar_dir = np.unique(trial_dat['trials_array'][:,5])[:8];\n",
    "trial_dat_id = np.unique(trial_dat['trials_array'][:,5],return_inverse=True)[1];\n",
    "\n",
    "for trial_id in range(251):\n",
    "    if dat_['seq'][0][trial_id]['T'][0,0] != 0:\n",
    "        dat_all[trial_dat_id[trial_id]].append(dat_['seq'][0][trial_id]['y'].T[:,63:]);\n",
    "\n",
    "dat_all = np.array([np.array(dat_all[ii]) for ii in range(8)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## randomly split into batches\n",
    "np.random.seed(666);\n",
    "trial_ls = [np.random.permutation(np.array_split(np.random.permutation(np.arange(dat_all[ii].shape[0])),24)) for ii in range(8)];\n",
    "\n",
    "x_all = [];\n",
    "u_all = [];\n",
    "cu_all = [];\n",
    "for ii in range(24): # 24 batches\n",
    "    x_tr = [];\n",
    "    u_tr = [];\n",
    "    cu_tr= [];\n",
    "    for jj in range(8): # 8 different directions\n",
    "        x_tmp = np.concatenate(dat_all[jj][trial_ls[jj][ii]])#[:,:-1];\n",
    "        cu_tmp = np.ones((x_tmp.shape[0],1))*jj;\n",
    "        u_tmp = np.ones((x_tmp.shape[0],1))*0.0;\n",
    "        x_tr.append(x_tmp);\n",
    "        cu_tr.append(cu_tmp);\n",
    "        u_tr.append(u_tmp);\n",
    "    x_all.append(np.concatenate(x_tr));\n",
    "    u_all.append(np.concatenate(u_tr));\n",
    "    cu_all.append(np.concatenate(cu_tr));\n",
    "\n",
    "x_all = np.array(x_all);\n",
    "u_all = np.array(u_all);\n",
    "cu_all = np.array(cu_all);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_all[:20];\n",
    "u_train = u_all[:20];\n",
    "\n",
    "x_valid = x_all[20:22];\n",
    "u_valid = u_all[20:22];\n",
    "\n",
    "x_test = x_all[22:];\n",
    "u_test = u_all[22:];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(666);\n",
    "vae = vae_mdl(dim_x=x_all[0].shape[-1], \n",
    "                   dim_z=4,\n",
    "                   gen_nodes=60, n_blk=2, mdl='poisson', learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chk_path = '../results/macaque_4d_999_vae.h5' ##999, 777\n",
    "mcp = ModelCheckpoint(model_chk_path, monitor=\"val_loss\", save_best_only=True, save_weights_only=True)\n",
    "s_n = vae.fit_generator(custom_data_generator(x_train, u_train),\n",
    "              steps_per_epoch=len(x_train), epochs=1000,\n",
    "              verbose=1,\n",
    "              validation_data = custom_data_generator(x_valid, u_valid),\n",
    "              validation_steps = len(x_valid), callbacks=[mcp]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(s_n.history['val_loss'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chk_path = '../results/macaque_4d_999_vae.h5'\n",
    "vae.load_weights(model_chk_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = vae.predict_generator(custom_data_generator(x_all, u_all),\n",
    "                                                steps = len(x_all));\n",
    "# post_mean, post_log_var, z_sample,fire_rate, lam_mean, lam_log_var, z_mean, z_log_var\n",
    "print(outputs[0].var(axis=0))  ## variance of each latent dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_pred_all = [];\n",
    "for ii in range(dat_all.shape[0]):\n",
    "    z_pred_tmp = [];\n",
    "    for jj in range(dat_all[ii].shape[0]):\n",
    "        z_pred_tmp.append(vae.predict([dat_all[ii][jj], np.ones((dat_all[ii][jj].shape[0],1))*(0.0)])[0]);\n",
    "    z_pred_all.append(z_pred_tmp);\n",
    "z_pred_all = np.array(z_pred_all);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## posterior mean\n",
    "c_vec = np.array(['red','orange','green','blue','indigo','pink','brown','gray'])\n",
    "c_all = np.array(np.concatenate(cu_all).reshape(-1), dtype='int');\n",
    "\n",
    "#link = {0:0,1:1,2:3};\n",
    "#link = {0:3,1:1,2:2};\n",
    "fsz = 14;\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "\n",
    "ax1 = plt.subplot(1,2,1);\n",
    "ax1.set_xlabel('Latent 1',fontsize=fsz,fontweight='normal');\n",
    "ax1.set_ylabel('Latent 2',fontsize=fsz,fontweight='normal');\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "plt.scatter(outputs[0][:,3], outputs[0][:,1], s=1, c=c_vec[c_all%8], alpha=0.5);\n",
    "plt.setp(ax1.get_xticklabels(), fontsize=fsz);\n",
    "plt.setp(ax1.get_yticklabels(), fontsize=fsz);\n",
    "\n",
    "ax2 = plt.subplot(1,2,2);\n",
    "ax2.set_xlabel('Latent 3',fontsize=fsz,fontweight='normal');\n",
    "ax2.set_ylabel('Latent 4',fontsize=fsz,fontweight='normal');\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "plt.scatter(outputs[0][:,2], outputs[0][:,0], s=1, c=c_vec[c_all%8], alpha=0.5);\n",
    "plt.setp(ax2.get_xticklabels(), fontsize=fsz);\n",
    "plt.setp(ax2.get_yticklabels(), fontsize=fsz);\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## posterior mean average accross trials/repeats\n",
    "c_vec = np.array(['red','orange','green','blue','indigo','pink','brown','gray'])\n",
    "c_all = np.array(np.concatenate(u_all).reshape(-1), dtype='int');\n",
    "\n",
    "#ndim = 2;\n",
    "#ndir = 0;\n",
    "#select = (np.concatenate(u_all).reshape(-1) == ndir);\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "ax1 = plt.subplot(1,2,1);\n",
    "ax1.set_xlabel('Latent 1',fontsize=fsz,fontweight='normal');\n",
    "ax1.set_ylabel('Latent 2',fontsize=fsz,fontweight='normal');\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "for ndir in range(8):\n",
    "    mean1 = mean2 = 0;\n",
    "    n_tr = len(z_pred_all[ndir]);\n",
    "    counter = 0;\n",
    "    for ii in range(n_tr):\n",
    "        if len(z_pred_all[ndir][ii]) >= 20:\n",
    "            counter += 1;\n",
    "            mean1 += z_pred_all[ndir][ii][:20,3];\n",
    "            mean2 += z_pred_all[ndir][ii][:20,1];\n",
    "    #print(counter);\n",
    "    ax1.plot(mean1/counter, mean2/counter, '-x', c=c_vec[ndir]);\n",
    "    \n",
    "plt.setp(ax1.get_xticklabels(), fontsize=fsz);\n",
    "plt.setp(ax1.get_yticklabels(), fontsize=fsz);\n",
    "\n",
    "ax2 = plt.subplot(1,2,2);\n",
    "ax2.set_xlabel('Latent 3',fontsize=fsz,fontweight='normal');\n",
    "ax2.set_ylabel('Latent 4',fontsize=fsz,fontweight='normal');\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "for ndir in range(8):\n",
    "    mean1 = mean2 = 0;\n",
    "    n_tr = len(z_pred_all[ndir]);\n",
    "    counter = 0;\n",
    "    for ii in range(n_tr):\n",
    "        if len(z_pred_all[ndir][ii]) >= 20:\n",
    "            counter += 1;\n",
    "            mean1 += z_pred_all[ndir][ii][:20,2];\n",
    "            mean2 += z_pred_all[ndir][ii][:20,0];\n",
    "    #print(counter);\n",
    "    ax2.plot(mean1/counter, mean2/counter, '-x', c=c_vec[ndir]);\n",
    "plt.setp(ax2.get_xticklabels(), fontsize=fsz);\n",
    "plt.setp(ax2.get_yticklabels(), fontsize=fsz);\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sample u\n",
    "u_fake = np.array([[np.ones((x_test[ii].shape[0],1))*jj for ii in range(len(x_test))] \n",
    "                   for jj in range(1)])\n",
    "\n",
    "## compute loglik\n",
    "np.random.seed(666);\n",
    "lik_all = compute_marginal_lik_poisson(vae, x_test, u_fake, 500, log_opt = True);\n",
    "lik_use = np.concatenate([lik_all[jj].mean(axis=0)-ssp.loggamma(x_test[jj]+1).sum(axis=-1) for jj in range(len(lik_all))]);\n",
    "\n",
    "## save as np.save(\"../results/lik_vae_chewie.npy\", lik_use) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute firing rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute firing rate for vae\n",
    "z_pred_all = [];\n",
    "for ii in range(dat_all.shape[0]):\n",
    "    z_pred_tmp = [];\n",
    "    for jj in range(dat_all[ii].shape[0]):\n",
    "        z_pred_tmp.append(vae.predict([dat_all[ii][jj], np.ones((dat_all[ii][jj].shape[0],1))*(0.0)])[3]);\n",
    "    z_pred_all.append(z_pred_tmp);\n",
    "z_pred_all = np.array(z_pred_all);\n",
    "\n",
    "## save as np.save(\"../results/fire_rate_vae_chewie.npy\",z_pred_all_vae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
